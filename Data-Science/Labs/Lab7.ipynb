{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Branded_Logo_CUDenver.PNG\" width=\"150\">\n",
    "\n",
    "## <center>CSCI 4580/5580 – Data Science – Spring 2025</center>\n",
    "<center>Lab 7: Logistic Regression and Random Forest</center><center><font color='red'>Deadline: April 13, 2025 - 11:59 PM</font></center><center>Total Points: 100</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Please note that this lab must be done individually. By submitting this lab, you certify that this is your own work, your code will be checked against other submissions and resources using automatic tools. Everyone should be getting a hands on experience in this course. You are free to discuss course material with fellow students, and we encourage you to use Internet resources to aid your understanding, but the work you turn in, including all code and answers, must be your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "You need to submit a single .ipynb file on Canvas, named your-lastname_your-first-name.ipynb. For example, if your name is John Smith, you should name the file smith_john.ipynb.\n",
    "- Please do not include extra files such as the input datasets in your submission.\n",
    "- Answer Questions 1 - 7 in the designated cells. Please do not add or remove any cells. \n",
    "- Please download your submission file after submission and make sure it is not corrupted. Use the 'Run All' option from the 'Cell' menu to ensure all cells run without any issues. We will not be responsible for corrupted submissions and will not take a resubmission after the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need Help?\n",
    "If you need help with this lab, please email me at sundous.hussein@ucdenver.edu or come to my office hours. We also encourage you to ask your questions on the designated channel for the lab on Microsoft Teams. This way, you may receive assistance from your classmates that might’ve ran through the same issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given enough data, Logisitic Regression should always do at least as well as Naive Bayes on binary-feature data. Let's try that out on the text dataset (named <b>words</b>) that can be downloaded from Canvas under Lab 7. Place it in the same directory as this notebook and unzip it.\n",
    "\n",
    "We'll also need the <b>MNIST</b> data from the last lab (Lab 6, but also available under Lab 7). Download it from Canvas and put it under the same directory as this notebook and unzip it.\n",
    "\n",
    "First, load the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iwords = np.loadtxt(\"words.imat.txt\")          # training data matrix in nnz x 3 form - rows are (doc, word, count) triples\n",
    "traincats = np.loadtxt(\"cats.imat.txt\")        # training labels in an ntrain x ncats matrix\n",
    "tiwords = np.loadtxt(\"testwords.imat.txt\")     # test data matrix in nnz x 3 form\n",
    "testcats = np.loadtxt(\"testcats.imat.txt\")     # test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data come as dense matrices with (row, col, val) triples in their rows. But they represent sparse matrices so we do the conversion next. Note that the matrix constructor uses wordcount>0 tests instead of the actual word counts which has the effect of making the word features binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sp.csr_matrix((iwords[:,2].astype(\"int\") > 0, (iwords[:,1].astype(\"int\"), iwords[:,0].astype(\"int\"))))\n",
    "ntrain = train.shape[0]\n",
    "nfeats = train.shape[1]\n",
    "\n",
    "test = sp.csr_matrix((tiwords[:,2] > 0, (tiwords[:,1], tiwords[:,0])),shape=(4000,nfeats))  # need to match the number of cols (words)\n",
    "ntdocs = test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we will concentrate on one label category, Category 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincat6 = traincats[:,6]\n",
    "testcat6 = testcats[:,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrclassifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and train it on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewebes05/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrclassifier.fit(train,traincat6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lrclassifier.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 1: Compute the accuracy of the predictions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91025\n"
     ]
    }
   ],
   "source": [
    "# Add code to score here (hint: this can be done in a single line of code)\n",
    "print(f'Accuracy: {sum(1 if testcat6[x] == preds[x] else 0 for x in range(len(preds))) / len(preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 2: How does this compare with Naive Bayes? In case you don't have the results handy, lets do it here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BernoulliNB docs](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Add code to train, predict, score here (see sklearn documentation above for more info)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train, traincat6)\n",
    "preds = clf.predict(test)\n",
    "print(f'Accuracy: {sum(1 if testcat6[x] == preds[x] else 0 for x in range(len(preds))) / len(preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond Accuracy: ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label prediction accuracy is a useful but sometimes misleading measure. E.g., for data with 10% positives, a predictor that always says \"no\" will be 90% accurate. It is also very often useful to control the ratio of positive/negative labels to minimize a loss function. E.g., false positives are generally more acceptable in computational marketing (it means you show an ad to someone who might not be interested) than false negatives (you failed to show an ad to someone who might be interest, and might generate some revenue for you). \n",
    "\n",
    "Logistic Regression computes the probability of a label and that output is useful for both richer evaluation methods, and for making more careful tradeoffs between positives and negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC (Receiver-Operator Characteristic) curve is a very useful tool for interpreting classifier performance. See the background material here:\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic .\n",
    "It shows the classifiers TPR (True-Positive Rate) vs FPR (False-Positive Rate) at various thresholds. The threshold isnt shown on the plot but can be inferred later. TPR and FPR are defined as:\n",
    "\n",
    "* TPR = TP / (TP + FN)   # based only on actual positive instances\n",
    "* FPR = FP / (FP + TN)   # based only on actual negative instances\n",
    "\n",
    "where TP = true positive, FN = false negative (actually a positive which is mislabelled), etc. \n",
    "Neither quantity involves a mix of positives and negatives. So ROC curves are insensitive to the actual ratio of positives to negatives. \n",
    "\n",
    "To use ROC, we first use a modified version of the \".predict\" method which returns label probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lrclassifier.predict_proba(test);\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From which you can see that there are 2 columns, i.e., one probability of false and one for true. Verify that the sum of every row is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the probabilities of cat6 membership = true, which is column 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6 = preds[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we'll do a ROC plot for it. ROC plots represent the performance of a classifier over a range of possible threshold values, showing the true positive rate and false positives rates at those thresholds. In Python, do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "rc = roc_curve(testcat6, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the X and Y coordinates of the ROC plot. To see it, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x724ea9d55460>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rc[0],rc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 3: What is the True positive rate at an FPR of 0.2 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9564089257913856\n"
     ]
    }
   ],
   "source": [
    "# Add your response here\n",
    "\n",
    "print(np.interp(0.2, rc[0], rc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the ROC curve is sometimes too much information, especially if you want to compare performance of many classifiers or datasets. The overall performance is well-characterized by the AUC or Area Under the Curve. Which is exactly what the name suggests, the area under the blue curve. Since a ROC plot lies in a 1 x 1 square, the area is always <= 1.0. A random predictor puts positives and negatives on a diagonal line with slope = 1, and so a random predictor has AUC = 0.5\n",
    "\n",
    "Lets check the AUC for our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637782435649894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(testcat6, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Thinking: Interpreting AUC scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score varies between 0.5 (random prediction) and 1.0. A common misconception is that a \"perfect\" predictor, i.e. a predictor that knows the exact probability of a label, will give a score of 1.0. That's incorrect. There are two sources of noise in the generation of a ROC plot:\n",
    "* The difference between the true and predicted probability of a label\n",
    "* The variance introduced by Bernoulli sampling to generate the label\n",
    "\n",
    "The latter is always present and depends on the distribution of label probabilities, the former depends on how good the model is. \n",
    "\n",
    "To see this, imagine a binary label distribution where each data label has a true probability of 0.5. A perfect predictor knows these probabilities but since they all the same, the sorted labels for the ROC plot would still be a random distribution of true and false. The ROC plot would have an AUC of 0.5. AUC scores very close to 1 are possible, but require that the true label distribution include a large fraction of probabilities close to either 1 or 0. That's because the variance of a Bernoulli variable is p(1-p), which is small if p is near 0 or 1. \n",
    "\n",
    "Let's estimate the ROC AUC for a perfect predictor on a similar distribution to our dataset. We can't know this distribution, but we can use the model's prediction  as an approximation to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll generate some uniform random numbers in [0,1], one for each test point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = npr.random(testcat6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate Bernoulli random numbers using the predictions as the underlying probability. We use the random numbers we just generated to do that. i.e. to generate a random Bernoulli variable with probability p, you generate a uniform random variable in [0,1] and test if (u < p). The probability that this test succeeds is exactly p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (a < preds6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847521057764689"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(x, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this number with the AUC you computed earlier. To be clear again what this number is, it is the score of a *perfect* label predictor with the label probability distribution that our classifier has. It is an estimate of how well our classifier could do on this dataset. \n",
    "\n",
    "This secondary AUC calculation is a useful normalizing test when interpreting AUC scores. A common mistake is to assume that a model with AUC 0.85 on dataset A is better (i.e. would score higher on a common dataset) than a model with a score of 0.70 on dataset B. This is not true. It depends strongly on the dataset. The model with score 0.70 may be generating perfect or near-perfect predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 1.00e+00, 1.00e+00, 0.00e+00, 2.00e+00, 3.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.00e+00, 1.00e+00, 2.00e+00, 3.00e+00,\n",
       "        0.00e+00, 3.00e+00, 1.00e+00, 2.00e+00, 5.00e+00, 1.00e+01,\n",
       "        8.00e+00, 6.00e+00, 9.00e+00, 5.00e+00, 1.10e+01, 1.00e+01,\n",
       "        8.00e+00, 2.60e+01, 2.50e+01, 2.00e+01, 2.60e+01, 3.20e+01,\n",
       "        3.30e+01, 4.80e+01, 4.10e+01, 6.00e+01, 6.60e+01, 7.00e+01,\n",
       "        6.90e+01, 9.60e+01, 1.08e+02, 1.20e+02, 1.03e+02, 1.26e+02,\n",
       "        1.39e+02, 1.42e+02, 1.22e+02, 1.32e+02, 1.13e+02, 1.27e+02,\n",
       "        1.52e+02, 1.91e+03]),\n",
       " array([-1.11984875e+01, -1.09745178e+01, -1.07505480e+01, -1.05265783e+01,\n",
       "        -1.03026085e+01, -1.00786388e+01, -9.85466902e+00, -9.63069927e+00,\n",
       "        -9.40672952e+00, -9.18275977e+00, -8.95879002e+00, -8.73482027e+00,\n",
       "        -8.51085052e+00, -8.28688077e+00, -8.06291102e+00, -7.83894127e+00,\n",
       "        -7.61497151e+00, -7.39100176e+00, -7.16703201e+00, -6.94306226e+00,\n",
       "        -6.71909251e+00, -6.49512276e+00, -6.27115301e+00, -6.04718326e+00,\n",
       "        -5.82321351e+00, -5.59924376e+00, -5.37527401e+00, -5.15130426e+00,\n",
       "        -4.92733451e+00, -4.70336476e+00, -4.47939501e+00, -4.25542526e+00,\n",
       "        -4.03145551e+00, -3.80748576e+00, -3.58351601e+00, -3.35954626e+00,\n",
       "        -3.13557651e+00, -2.91160676e+00, -2.68763701e+00, -2.46366725e+00,\n",
       "        -2.23969750e+00, -2.01572775e+00, -1.79175800e+00, -1.56778825e+00,\n",
       "        -1.34381850e+00, -1.11984875e+00, -8.95879002e-01, -6.71909251e-01,\n",
       "        -4.47939501e-01, -2.23969751e-01, -1.57277374e-10]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(preds6),50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is an enormous range of values. Most probabilities are very close to zero or one, which is why this dataset has such a high ROC AUC score.\n",
    "\n",
    "Suppose instead we had a dataset with a less wide distribution. We can use a lognormal distribution to simulate this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob = np.minimum(npr.lognormal(-4,1,10000),1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good model, e.g. for the range of user's probabilities of clicking on an ad. Let's look at a histogram of the log10 of the values (a direct histogram will be too squashed near 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 4.000e+00, 1.900e+01, 3.500e+01, 8.400e+01, 2.600e+02,\n",
       "        4.760e+02, 8.270e+02, 1.221e+03, 1.537e+03, 1.573e+03, 1.442e+03,\n",
       "        1.079e+03, 6.980e+02, 4.330e+02, 2.100e+02, 7.000e+01, 2.400e+01,\n",
       "        3.000e+00, 4.000e+00]),\n",
       " array([-3.54089692, -3.36609211, -3.1912873 , -3.01648249, -2.84167768,\n",
       "        -2.66687287, -2.49206806, -2.31726325, -2.14245844, -1.96765363,\n",
       "        -1.79284882, -1.61804401, -1.4432392 , -1.26843438, -1.09362957,\n",
       "        -0.91882476, -0.74401995, -0.56921514, -0.39441033, -0.21960552,\n",
       "        -0.04480071]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(cprob),20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's our distribution of virtual users. Notice that the values (which represent click probabilities) range over several orders of magnitude since we plotted their log10. Next we simulate users' click behavior. Once again we generate a uniform random variable u for each user, and output 1 if u < the user's click probability given by cprob. \n",
    "\n",
    "Finally we compute the AUC on that data, which is the score of a perfect predictor on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778038807558145"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = npr.random(cprob.shape)\n",
    "x = (a < cprob)\n",
    "roc_auc_score(x, cprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's the AUC score for a perfect predictor on this (artificial) dataset. This is lower than the *real* predictions on the RCV1 text dataset. So be careful when interpreting AUC scores. There is no absolute scale for them, and they depend a lot on the dataset.\n",
    "\n",
    "Another important point is that the AUC value for mid-range scores can have quite a lot of variance. Try re-evaluating the last cell to see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 4: What changes do you think you should make to the distribution cprob to increase the ROC AUC score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking in the real world, we could look to finetune the classifier, preprocess and remove noise from the data, look to regularize based on proportionality of the data classes, and ensure there isn't overfitting/underfitting in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests are an extremely accurate classifier for datasets of moderate size. Let's try them out here. We'll load the MNIST data now, but first its probably a good idea to restart your kernel to reduce memory use. Click on the \"Kernel\" menu above and then \"Restart\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0=np.loadtxt(\"train.fmat.txt\")\n",
    "test0=np.loadtxt(\"test.fmat.txt\")\n",
    "train = np.transpose(train0[:,0:4000])\n",
    "test = np.transpose(test0[:,0:2000])\n",
    "traincats = np.loadtxt(\"ictrain.imat.txt\")\n",
    "testcats = np.loadtxt(\"ictest.imat.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're going to tuning the parameters of RFs on some test data, we need to split our test set into a validation set and a final test set to avoid overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test[0:1000,:]\n",
    "finaltest = test[1000:2000,:]\n",
    "validationcats = testcats[0:1000]\n",
    "finaltestcats = testcats[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=30, n_estimators=20, n_jobs=4,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=20,n_jobs=4,bootstrap=True, random_state=42)\n",
    "rfclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "np.mean(preds == validationcats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the [scikit-learn documentation for Random Forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier) to make sure you understand the meaning of all the parameters in the call to the RandForestClassifier constructor. Which ones do you think will improve accuracy the most? **NOTE** you don't need to tune n_jobs. Its the number of threads that the classifier code runs and it only affects running time. It should be set to the number of cores that your processor has. \n",
    "\n",
    "Try tuning the classifier with the validation set above to get better than 90% accuracy on the validation set. Don't touch the final test set until you're done tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 5: Make a table with at least two values you tried each for criterion, max_features, n_estimators, and bootstrap. What trends to you notice for each one? \n",
    "\n",
    "> Question 6: Report your validation and final test accuracy. Include all the parameters you used, e.g., include the line where you invoked the RandomForestClassifier constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896\n",
      "0.847\n",
      "0.907\n",
      "0.891\n",
      "0.887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmax_features: 20 (0.891), 40 (0.887) - worse performance in both, likely due to overfitting/underfitting\\nn_estimators: 10 (0.847 observed), 30 (0.907 observed) - slightly better performance when increased, worse performance when decreased\\nboostrap: True (0.9 observed), False (0.896 observed) - slightly worse accuracy without boostrapping\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code and response for Question 5 here\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=20,n_jobs=4,bootstrap=False, random_state=42)\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "print(np.mean(preds == validationcats))\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=10,n_jobs=4,bootstrap=True, random_state=42)\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "print(np.mean(preds == validationcats))\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=30,n_jobs=4,bootstrap=True, random_state=42)\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "print(np.mean(preds == validationcats))\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=20,n_estimators=20,n_jobs=4,bootstrap=True, random_state=42)\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "print(np.mean(preds == validationcats))\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=40,n_estimators=20,n_jobs=4,bootstrap=True, random_state=42)\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "print(np.mean(preds == validationcats))\n",
    "\n",
    "'''\n",
    "max_features: 20 (0.891), 40 (0.887) - worse performance in both, likely due to overfitting/underfitting\n",
    "n_estimators: 10 (0.847 observed), 30 (0.907 observed) - slightly better performance when increased, worse performance when decreased\n",
    "boostrap: True (0.9 observed), False (0.896 observed) - slightly worse accuracy without boostrapping\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907\n"
     ]
    }
   ],
   "source": [
    "# Add your response/code for Question 6 here (either a written response or reporting with code are fine)\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=30,n_jobs=4,bootstrap=True, random_state=42)\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "print(np.mean(preds == validationcats))\n",
    "\n",
    "# almost 1% accuracy increase from original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rfclassifier.predict(finaltest)\n",
    "np.mean(preds == finaltestcats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 7: Reflect on and explain any differences between your validation and final test accuracy scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was about a 3 % decrease from validation to final test accuracy. This is quite good, relatively speaking, considering the final test accuracy was still around 88%. A likely reason for this was due to slight overfitting, which would be worth analyzing further for future reference. However, this could also be due to randomness in our training/testing as well as RF Classifier random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
